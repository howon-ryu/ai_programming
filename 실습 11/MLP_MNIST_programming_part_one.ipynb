{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron with MNIST handwritten digits classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 다운로드 (Train data와 Test data 분리하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 첫번째 batch 데이터의 크기와 타입을 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 첫번째 batch 데이터를 시각화하여 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n",
    "    plt.title('Class: '+str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로그래밍 과제: MLP 모델의 학습과정 중 forward propagation을 계산하는 함수 구현하기\n",
    "### - input layer (입력층), hidden layer (은닉층), output layer (출력층) 으로 이루어진 모델을 이용\n",
    "### - 하나의 hidden layer (은닉층)만 이용\n",
    "### - 첫번째 batch 만 이용하여 계산을 수행 (다시 말해 batch_idx = 0 일 경우에만 수행하기 위해 함수안의 가장 마지막에 break문을 사용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_func(outputs):\n",
    "    # 아래에 코드를 채우세요.\n",
    "    \n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label):\n",
    "    # 아래에 코드를 채우세요.\n",
    "    \n",
    "    return one_hot_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(train_loader):\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        print(image.size())\n",
    "        image = image.view(-1, 28 * 28)\n",
    "        print(image.size())\n",
    "        \n",
    "        # Weight(가중치)를 초기화 (random 함수 이용)\n",
    "        # 아래에 코드를 채우세요.\n",
    "        W_ih = \n",
    "        W_ho = \n",
    "        \n",
    "        # Forward propagration 계산하기\n",
    "        # 아래에 코드를 채우세요.\n",
    "        # ...\n",
    "        # outputs = \n",
    "        \n",
    "        # Forward propagation을 처리하고 얻은 결과 값(outputs)을 ReLU 함수에 적용하기\n",
    "        # 참고: ReLU() 함수를 구현하거나 직접 ReLU computation을 풀어서 코딩할 것        \n",
    "        predicted_outputs = ReLU_func(outputs)\n",
    "                \n",
    "        # 주어진 label=(BATCH_SIZEx1 = 32x1)을 one-hot encoding을 통해 expected_outputs=(BATCH_SIZE*Labels = 32x10)로 변환해주는 함수를 구현하고 값을 반환하기\n",
    "        expected_outputs = one_hot_encoding(label)\n",
    "        \n",
    "        # 최종적으로 얻은 예측 값(predicted_outputs)과 기대 값(expected_outputs)을 비교\n",
    "        # 아래에 코드를 채우세요.\n",
    "        # ...\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
